{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Neural Networks.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J-cKsCZ6axWv",
        "colab_type": "text"
      },
      "source": [
        "# HW #7 Neural Networks\n",
        "\n",
        "In this HW, we'll be exploring a visual proof of the universal approximation theorem and building (from scratch) a neural network that will approximate a pretty ridiculous function.\n",
        "\n",
        "Head over to [this site](http://neuralnetworksanddeeplearning.com/chap4.html) and read from the beginning of the page until the \"Many Input Variables\" section. (You do not need to read the \"Many Input Variables\" section and beyond but are certainly welcome to do so!) You'll read the introduction, the \"Two Caveats\" section, and the \"Universality with One Input and One Output\" section.\n",
        "\n",
        "Your answers to problems 1-5 should come from directly this reading."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uB_nGvAvaxW2",
        "colab_type": "text"
      },
      "source": [
        "**Problem 1**: Summarize the Universal Approximation Theorem. (Don't copy it; use your own words!)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Msiu9YDmaxW3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# The Universal Approximation theorem is having an algorithm ability in approximating any arbitary function in the universe.\n",
        "# Genrally, neural networks are known as Universal Approximators. So a neural network with single hidden layer with n-no.of neurons gains the ability in approximating any function.\n",
        "# In simple way universality means ability to do anything. Neural networks had powerful combination of both learning function and universality. The neural network architecture provides\n",
        "# these kind of feasibilities."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ICxqzmDIaxW_",
        "colab_type": "text"
      },
      "source": [
        "**Problem 2**: Summarize the two caveats the author uses to describe the statement \"a neural network can compute any function.\""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fGMDKVOkaxXD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# By having of sufficient hidden neurons in the hidden layer, neural networks can gain the ability in producing desired output with the desired accuracy.\n",
        "# Neural networks are majorty having of continuous function, even if there is discontinuous function the neural network continuous function can approximate that. "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lx1kc_QEaxXJ",
        "colab_type": "text"
      },
      "source": [
        "**Problem 3:** For a sigmoidal activation function to closely resemble a step function, how would you describe the value of $w$? What constraints exist on the value of $b$? How do we calculate $s$? What does the value of $s$ indicate?\n",
        "\n",
        "Try playing around with the applets on [this site](http://neuralnetworksanddeeplearning.com/chap4.html) to test how different parts of the perceptron affect the output. This should be helpful in answering the questions above."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "umPxYissnQrx",
        "colab_type": "text"
      },
      "source": [
        "**Answer**: \n",
        "  As the weights (w)  should be set to high value. If the bias (b) value keeps decreasing or incresing there is no change in the shape of the graph. by adjusting bias we can set up the starting position of step funtion.\n",
        "The \"S\" can be calclated as -(bias(b)/weights(w)). The value of S indicates the position of the step.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XPyS6AeOaxXP",
        "colab_type": "text"
      },
      "source": [
        "**Problem 4**: When the author wants us to approximate $f(x)=0.2+0.4x^2+0.3x\\sin(15x)+0.05\\cos(50x)$ with a neural network, the function on the applet where we manipulate the values of $h_i$ is not $f(x)$. It's a different function. What is this function, and where on the feedforward Neural Network is can the vaule of this function be collected?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y4MbbrNwsGhN",
        "colab_type": "text"
      },
      "source": [
        "** Answer **:  It is the actual function that the neural network is calculating. The function  corresponds over the weighted combination of the outputs from the hidden layers towards the output. The value of the function can be seen on the output layer. Since the outputs of all hidden layers are contributed towards the final output layer in our network. It is deciding function in getting of true outputs from the data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Ws174ZVaxXY",
        "colab_type": "text"
      },
      "source": [
        "**Problem 5**: The author asks you to find values of $h_i$ that make your neural network closely approximate $\\sigma^{-1}\\circ f(x)$. Record your values of $h_i$ here and your best \"average deviation\" score. Let's name the $h$s from top to bottom on the graph as $h_1$, $h_2$ ,,,, $h_5$,"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2CDj2XfgaxXa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# h1 = -1.2, h2 = -1.4, h3= -0.3, h4=-0.9, h5=1.3 , optimal average deviation = 0.38"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IbLaLSKRaxXf",
        "colab_type": "text"
      },
      "source": [
        "**Problem 6**: Build the neural network from your work in Problem 5 here with MLPClassifier.\n",
        "\n",
        "A few things to keep in mind:\n",
        "* How many inputs are there? \n",
        "* How many outputs are there?\n",
        "* How many neurons are in the hidden layer?\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WwUSykKG2Q8e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import warnings; warnings.simplefilter('ignore')\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.linear_model import LogisticRegression, LogisticRegressionCV\n",
        "from sklearn.neural_network import MLPClassifier, MLPRegressor\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from matplotlib import pyplot as plt\n",
        "from sklearn.metrics import mean_squared_error\n",
        "%matplotlib inline"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7OuDzfHv2UM9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X = pd.DataFrame(np.linspace(0,1,1000))\n",
        "y = pd.DataFrame(0.2 + 0.4 * X**2 + 0.3 * X * np.sin(15*X) + 0.05 * np.cos(50*X))\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RJlauoxz2UZl",
        "colab_type": "code",
        "outputId": "5952b092-f903-4419-b4ce-68b294030337",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "# activation = relu\n",
        "mlp = MLPRegressor(hidden_layer_sizes=10, learning_rate_init=0.091, random_state=0)\n",
        "mlp.fit(X_train,y_train)\n",
        "accuracy = mlp.score(X_test,y_test)\n",
        "y_pred = mlp.predict(X)\n",
        "MSE = mean_squared_error(y, y_pred)\n",
        "print(\"Accuracy: {}\".format(accuracy,MSE))\n",
        "print(\"MSE: {}\".format(MSE))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy: 0.8182586909073631\n",
            "MSE: 0.008273983854967458\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E4VwpHTkaxXo",
        "colab_type": "text"
      },
      "source": [
        "**Problem 7**: Once you've built the neural network with the structure described in Problem 6, use `np.linspace` to generate 1000 values of $x$ between 0 and 1 and estimate the performance of your neural network using mean squared error.\n",
        "\n",
        "Recall that mean squared error(MSE) is given by:\n",
        "\n",
        "$$\n",
        "\\frac{1}{n}\\sum_{i=1}^n (\\hat{y}-y)^2\n",
        "$$\n",
        "\n",
        "\n",
        "* Your $\\hat{y}$ in this case are your predicted values from your neural network for each of the $x$ that you generated using `np.linspace`. Make sure to take into account the final activation function!\n",
        "* Your $y$ values are the actual observed values of $f(x)=0.2+0.4x^2+0.3x\\sin(15x)+0.05\\cos(50x)$ for each of the $x$ that you generated using `np.linspace`.\n",
        "* Use  [MLPRegressor](https://scikit-learn.org/stable/modules/generated/sklearn.neural_network.MLPRegressor.html#sklearn.neural_network.MLPRegressor) for this work.\n",
        "* Plot  $f(x)$ curve overlapped with the curve predicted by your trained Neural Networks for x between 0 and 1\n",
        "* Try different learning rates"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Kh0CvzN3C12",
        "colab_type": "code",
        "outputId": "d98ddbab-c9f9-4ae1-c866-56bdf21eff02",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "y_pred = mlp.predict(X)\n",
        "MSE = mean_squared_error(y,y_pred)\n",
        "print(MSE)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.008273983854967458\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bt8zgncL56pv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def plot_hyper_param_plots(x, y, y_pred, xlabel):\n",
        "    plt.plot(x, y, label='actual')\n",
        "    plt.plot(x, y_pred, label='predicted')\n",
        "    plt.xlabel(xlabel)\n",
        "    plt.ylabel('Test Accuracy')\n",
        "    plt.legend(loc='upper left')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XrxPNW9B3Exz",
        "colab_type": "code",
        "outputId": "13271c52-e5da-499d-cee9-b20362ac8db2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 278
        }
      },
      "source": [
        "plot_hyper_param_plots(X, y, y_pred, \"X\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAEGCAYAAABsLkJ6AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAIABJREFUeJzt3Xd8XNWZ+P/PjEa9995sy8e9YoNt\nXABTQg8QSEgvS7JpkM2mLtldfilsCi+y2RbyTUJIAiEEQkIHd9x7L0dW7733Kff3x4xluUgalSnS\nPO/XSy9Lc8s81yPd595zzn2OyTAMhBBCBB6zrwMQQgjhG5IAhBAiQEkCEEKIACUJQAghApQkACGE\nCFAWXwfgrsbGznEPV4qPj6C1tWcyw/F7csyBQY45MEzkmJOTo03DLQuIOwCLJcjXIXidHHNgkGMO\nDJ465oBIAEIIIa4kCUAIIQKUJAAhhAhQkgCEECJASQIQQogAJQlACCEClCQAIYQIUJIAhBDCTzkM\nB++VbaOwqcQj+5cE4CXHjh2htbVlzNvdccdNHohGCDEVnG4+x99L3mZf5RGP7F8SgJe8+eZr40oA\nQojAtal8BwAb8ld5ZP9TphaQv+ru7uKJJx6nt7eXvr4+vva1b9Dd3cUzz/wvZrOZjRtvIT9/Bjt3\nbqe0tIQf/OAnfPazH+XNN7cA8Pjj3+S++x4kKyub73//XwGw2Ww8/vgTZGZm+fLQhBA+VNJeTnF7\nKfMT55ATl0ljY+ekv8e0SQAvbS3i4LmGqy4LCjJht4+9ltyKOSk8eOOsEddpbm7mzjvvZd26DRw+\nfJDnn3+O4uIi/u//fktMTAzf+c7Xueee+5g1azb/9E/fJC0tbZj9NPHpT/8Dy5Zdwxtv/J2//vUv\nfOUrXxtzzEKI6WFzhfPq/+ac9R57j2mTAHwlISGR5577NX/60x+wWq309fUSEhJCfHw8AD/5yc/d\n3s/Pf/4zfvObZ+js7ECpuZ4MWwjhx+p7GjnReJrc6Gxmxc3w2PtMmwTw4I2zhr1aT06O9sjtE8BL\nL71AUlIK3/ve9zl37gw/+tETOBzu323YbDYAfvObZ7j22uu4994H2LZtM3v27PJIvEII/7el4n0M\nDDbmrsdkGraa84RJJ/AEtbe3DbbV79ixjYiISBwOO42NDRiGwTe/+RidnZ2YzWbsdjsAJpOJvr4+\n+vr6KCzUALS1OfdjGAa7du3AarX67JiEEL7T3t/J/rrDJIUnsiR5gUffa9rcAfjKbbfdwQ9+8G9s\n27aZ++9/kM2b3+OTn/w0jz/+LQBuvHEj0dHRLFmyjMcf/xZPPvkU9977AI888kny8mYMNvXcc899\nPP30T0lLy+CBBx7iJz/5IQcO7PPloQkhfGBH1W5sDhsbc9ZhNnn2Gt1kGOOeaMurJjIjmCebgPyV\nHHNgkGOeXvpsfTy+50mCTGa+v/q7hAQFAxM75oCfEUwIIaaCPbUH6bX1siFrzeDJ35MkAQghhB+w\nO+xsrdhJiDmYtVmeefDrcpIAhBDCDxxuOE5rfxurM1YSFRzplfeUBCCEED5mGAabyrdjNpm5MXut\n195XEoAQQvjY2ZZCarrrWJayiMTwBK+9ryQAIYTwsU2usg8bPVj24WokAfiBxx//JkeOHOKtt15n\nx45tw663bdtmt/f5xz/+kd/85pnJCE8I4UHlHZUUthYxJ76A7OhMr763JAA/cvvtd7F+/Q1XXWa1\nWvnzn1/wckRCCE+7UPRtY653r/5BngSesLfeep39+/fQ3d1NY2MDDz74MH/4w7Ncd90a4uPjueOO\nu3nyye9js1kxm81861vfIy0tjeeff47Nm98lLS2d7u5uwFkPKC4ujvvvf4if//xnnDlziqCgIL7x\nje/w6quvUFxcxM9+9h987Wvf4Cc/+SE1NdXYbDY+97kvsHz5Cg4dOsAvfvEUCQmJZGamk5CQ4uP/\nHSHESJp6mznacJKsqAzmxBdgdzgore2krbOfjKRIMpI8Oxpo2iSAvxa9wdGGk1ddFmQ2YR9DgbYL\nlqYs5L5Zd466XmlpCb/97fN0dXXxqU99BLPZzHXXrea661bz5JP/Hx/+8EdZseJa9u7dxXPP/Zov\nfvFRXn31ZZ5//mXsdhsPPnjvJfs7eHA/DQ31/OpXv+PYsSNs2bKJhx/+OGfOnOKf//nbvPPOmyQm\nJvGd7/wrbW1tPProF3juuRd55pn/5nvf+z4FBbP57nf/SRKAEH5uS8VODAxuzllPYWUbv3tHU9/S\nM7h8aUESn7ljLskeev9pkwB8acmSZVgsFuLi4oiOjqamppp58+YDcOrUCSoqynnuud/gcDiIi4un\nurqS/PwZhIaGAqFXlH4uLDzHwoWLB/e9ZMkyamtrBpefOnWC48ePcuLEMQD6+/uxWq3U1tZSUDAb\ngBUrVtDS0uGFoxdCjEfXQDd7aw+SEBZPd30yz7x7DMOANQvSyE6N5pBu4Oj5Jn76wlF+9phnmoem\nTQK4b9adw16te7p2yNDyz4bhrPZpsTgf47ZYgvn+939MUlLS4Dpnz57GNKTIk2E4Ltmf2Rx0xWtD\nWSzBfOITn+Hmm2+7bLuh+5waNZ6ECFQ7qvdgdVgpCF3K798uJDI8mC/ft5DZ2XEAbFyexXPvnGPn\niVr+sqWQD6zInvQYpBN4Epw+fQK73U5bWxs9Pd3ExMQOLps3bwE7d24H4PDhg7z33jtkZmZRXl6K\n1Wqlu7sLrc9esr+5c+dx5MghwHk38NRTP8ZkulhOet68Beza5ew4am1t4Zln/geApKRkKirKMAyD\nAwcOePqwhRDjNGAfYEfVbsKCwtm13UJISBBff2jJ4MkfwGw28fFbFfden8/K+VefSXCips0dgC+l\npWXwve99m+rqSh555Iv8+te/HFz22c8+wo9+9ASbN7+LyWTiu9/9N2JiYvnAB+7k85//NBkZmcyZ\nM/+S/S1ZsoydO3fwxS9+DoCvf/3bJCUlYbNZefzxb/Hv//5Djhw5yBe+8Bnsdjuf+cwjADzyyBd5\n/PFvkZaWTkaGZ35hhBATt7f2EN3WHkKaFTarmS9/aAG5adFXrGcJMnP39fkea8WQctAT9NZbr1NS\nUsyXv/yYR/Y/XtO5ZO5w5JgDw1Q/ZrvDzhP7fkpLbzs9R9dx27KCUecel3LQQggxDRxrPEVzXwvW\nhgxyEhL54DrPzfk7GmkCmqDbb7/L1yEIIaYIwzB4p3QbGEDTDB75yHyCLb67Dpc7ACGE8JJzrUXU\n9NRgb03loTWLPf6g12gkAQghhJf8+eS7AOQFLeGGpd6t+3M1Hm0CUko9DVyH84bnUa31wSHLvgR8\nDLADh7TW/tWLKoQQk+hA6Xka7RWYuhP54i1rMZmG7Zv1Go/dASil1gMFWutVwGeBXwxZFgN8A1ir\ntb4emKeUus5TsQghhC/19tt4/vg7ANw+40ZiIkN8HJGTJ5uAbgL+BqCdTzrFu078AAOuryillAWI\nAFo8GIsQQviEw2HwP2/sxxpdRSTxfGDeNb4OaZAnm4DSgMNDfm50vdahte5TSj0BlAC9wIta68KR\ndhYfH4HFEjTuYJKTr3zIYrqTYw4Mcsz+yzAMfv33U5zvP4bFZPDxa+4kJSVm9A2vwhPH7M1hoIMN\nXq47ge8Cs4EOYKtSarHW+vhwG7e29gy3aFRT/cGR8ZBjDgxyzP7LMAz+tOU8m4+WEr60itiQGOZG\nzR1X7BN8EGzYZZ5MADU4r/gvyABqXd/PBUq01k0ASqmdwHJg2AQghBBTRU+flWffPsdh3Uj8rDr6\nzHZuzFmLxexfj155sg/gPeABAKXUMqBGa30hhZUBc5VS4a6frwHOezAWIYTwuI7uAd49UMF3frWP\nw7qRguxoLKllhFvCWJNxra/Du4LH0pHWeo9S6rBSag/gAL6klPoU0K61flUp9VNgm1LKBuzRWu/0\nVCxCCDGZ+gfsVDR0UtXQRV1LL/WtPdS19NDY1othQGhIEPevn0F0di1/Luzm5pwNhFvCfB32FTx6\nP6K1/vZlLx0fsuwZQGYtF0JMGZUNXby+u5RjRU3Y7JfWp4yOCKYgK47ls5O5dn4qUeEWvr//JSym\nIDZkr/FRxCPzrwYpIYTwQ4Zh8PruMl7bXYbDMMhIimRBfgLZKVGkJ0aSmhBOZFjwJdscazxFQ08T\nq9NXEBcaO8yefUsSgBBCjMAwDP64qZBtR6pJjAnj47cqFs5IGPFJXsMw2Fy+HYCbcjwzneNkkAQg\nhBAj2HK4im1HqslKjuLrDy0mNip01G2K28so7ahgYdI80iJTvBDl+EgxOCGEGEZVYxd/3lpETEQw\nj31okVsnf4DNFdsBuDlng+eCmwSSAIQQ4ioMw+CP72rsDoNP3z6XhBj3RvHUdtdzsuksM2JzmRmX\n59kgJ0gSgBBCXMVh3UhhVTtLC5JYPCvJ7e02V+wAYKOfX/2DJAAhhLiCYRi8sacMkwk+dMPI8/UO\n1dbfzsG6o6RGJLMwaa4HI5wckgCEEOIyJ0taqGjoYsWcFNISItzebnvlbuyGnZty1mE2+f/p1f8j\nFEIIL9t6pAqA26/LdXubXlsvO6v3ERMSzcrUZZ4KbVJJAhBCiCFaOvo4WdLMjIwYclLdL8G8q3o/\nffY+bsi6nuCg4NE38AOSAIQQYohdJ2sxDFi3OMPtbWwOG9sqdxEaFML1mVNnckNJAEII4WIYBntP\n1xMSbGbFHPcf4DpYf4z2gQ7WZFxLRHD46Bv4CUkAQgjhUt3UTX1LD4tmJBIe6l6hBIfhYHPFDswm\nMzdmr/VwhJNLEoAQQrgc1o0ALFfuX/2fbj5HXXc916QuIT4szlOheYQkACGEcDmsG7AEmVk0M9Ht\nbS4++OW/Rd+GIwlACCGA+pYeqhq7WZCf4HbzT2l7OUVtpcxLVGRGpXs4wsknCUAIIYATJc0ALCkY\ne9kHfy/6NhxJAEIIAZwubQFgQX6CW+s39DRyvPE0OdFZFMTN8GRoHiMJQAgR8Gx2B7qijfTECLer\nfm6peB8Dg5tzN4w4OYw/kwQghAh4xdXt9FvtzM9z7+q/Y6CTfXWHSQpLYEnyAg9H5zmSAIQQAe+U\nq/lnvpvNPzsqd2Nz2LgpZ/2UKPo2nKkbuRBCTJIzZa0EmU2onNHH8ffZ+nm/ei9RwZFcl36NF6Lz\nHEkAQoiA1j9gp6K+k7z0aMJCRh/+ubf2ID22XtZnrSZkihR9G44kACFEQCupacfuMCjIGv3q3+6w\ns6XifULMwazLWu2F6DxLEoAQIqCdr2oHoCArdtR1Dzccp7W/jVUZK4kKjvR0aB4nCUAIEdDOV7UB\nMCtz5ARgGAabK3ZgwjTlir4NRxKAECJg2R0Oimo6SE+MIDoiZMR1z7Wcp7qrlmUpi0gKd2+0kL+T\nBCCECFhVDd30D9jdav/fVLEdgI25U6/o23AkAQghAlZhpbP5Z7T2/4rOKnRrEXPiC8iJzvJGaF4x\nagJQSv1RKbXBC7EIIYRXFde41wG8uXzqlnweiTt3AG8BjymlTimlvqOUmno1T4UQ4irK67uICLWQ\nHDf8NI5NvS0caThBZlQ6cxIKvBid542aALTWL2it7wVWAZXAS0qp1+SuQAgxlfUN2Gho6SEnNWrE\nYm5bK11F33KmbtG34bjVB6CUCgPuAj4GBAObgG8opZ7wYGxCCOExlQ1dGEBOavSw63QNdLOn5iAJ\nYfEsS1nkveC8xJ0+gP8HFAPrgX/RWl+ntf4v4E7XlxBCTDkV9V0A5KRGDbvO+9V7sDqs3Ji9liBz\nkLdC8xp37gAOA0pr/Xmt9WGllBlAa20An/dodEII4SHl9Z3A8HcAA/YBdlTtIcISzqr0Fd4MzWvc\nSQD1wAtDft6jlPoggNb6kEeiEkIID6uo7yTYYiY9MeKqy/fVHqLL2s26rNWEWUK9HJ13uJMAvgF8\ncsjPt7peE0KIKclmd1Dd2E1WchRB5itPgw7DwZaK97GYLWzIWuODCL3DnQRg0lq3XvhBa90OODwX\nkhBCeFZ1Yzd2h0HuMO3/xxpP0dTXwnVpy4kOGb6PYKobvfg1HFVKPQ9sx5kwbgOOu7NzpdTTwHWA\nATyqtT44ZFk28CcgBDiitf7C2EIXQojxqRih/d8wDDaVb8OEiZty1nk7NK9y5w7gyziHfS4DFgOv\nAF8ZbSOl1HqgQGu9Cvgs8IvLVnkKeEprvRKwK6VyxhK4EEKM18URQFcmgPNtxVR0VrM4eQEpEcne\nDs2rRr0D0Fo7gN+5vlBKWYDngY+MsulNwN9c+zirlIpXSsVorTtcI4nWXtiH1vpL4z0AIYQYq/KG\nTswmE1nJV9b031QxPcs+XM2oCUAp9TDOq/XEIS+/78a+03AOIb2g0fVaB5AMdAJPK6WWATu11t8Z\naWfx8RFYLOMfh5ucPPzDHtOVHHNgkGMeG4fDoLqxi6zUKDIzLq0CWt5WxZlmzdzkAlbOmj/RMCeV\nJz5nd/oAvgaswHnVfzfwMNA0jvcyXfZ9JvCfQBnwplLqDq31m8Nt3NraM463dEpOjqaxsXPc209F\ncsyBQY557Opaeujtt5OZGHHFfv5y5m0ANqRf71f/rxM55pEShzt9AG1a6yrArLVu11r/H/A5N7ar\nwXnFf0EGUOv6vgko11oXa63twBbAv9KtEGJaGq4DuLWvjUP1x0iPTGVeovJFaF7nTgIwlFK3A9VK\nqcddD4HlurHde8ADAK5mnhqtdSeA1toGlCilLpTWWw7oMUcvhBBjVF7nTAC5lyWArZU7cRgObspZ\nj9kUGFOluHOUnwDqgMeAGTiv/h8bbSOt9R7gsFJqD84RQF9SSn3qwlPErn0861reDrw+jviFEGJM\nLt4BXBzf32PtYXfNfmJDYliRusRXoXmdO30At2itf+/6/jNj2bnW+tuXvXR8yLIi4Pqx7E8IISbC\nMAzK67tIig0jIix48PWd1fvotw9we/7NWMzunBanB3fuAB5USgXeMAMhxLTT2tlPV6/1kuYfq93K\ntqpdhAWFsSbjWh9G533upLpgoEwpdRYYuPCi1vpGj0UlhBAecLUS0Afqj9A50MXNORsIt4T5KjSf\ncCcB/MTjUQghhBdcPgLIYTjYXLGDIFMQG7Knb9G34biTAKwej0IIIbzg8jkATjadoaGniVXpK4gL\nHXli+OnInQTwwyHfhwBzgT249zSwEEL4jYr6LmIigomLCgFgU/mFsg/Tu+jbcNypBbR26M9KqTTg\nBx6LSAghPKCr10pzRx8L8hMwmUwUt5VR2lHOwqS5pEWm+jo8nxjz0w5a6zpgngdiEUIIj7nQ/p+b\n5mz+2VSxHYCNORt8FJHvuVMM7lmc9fwvyLnsZyGE8HtDS0DXdddzsukM+TG5zIzN821gPuROH8Cu\nId8bOKt5vuOZcIQQwjOGPgG8ucJZd/Lm3PWYTKaRNpvW3GkCehFnQbjfaK1/C8QjdwBCiCmmvL6T\nsJAgQsKtHKg7QkpEEguTArs1250E8DuczT4XxAG/v/qqQgjhf/qtdupaeshJiWJH1W5shp2N2YFT\n9G047hx9stb66Qs/aK1/CiR4LiQhhJhcVQ1dGAZkpIays3of0SFRrExb5uuwfM6dBBA6pGwzSqkl\nQKjnQhJCiMl1of2/P7qMPnsfN2RdT3BQ8ChbTX/udAL/E/COUioMZ8LoxFkiWgghpoTy+k4wOSga\nOEpIUAhrM6/zdUh+wZ0Hwfa67gCScXb+trgmdBFCiCmhvL6L4KRaumyd3Ji9lojgCF+H5BdGbQJy\nTeDyN611vda6Adg1ZFIXIYTwaza7g+rGTkIzyzGbzNyQLdOQXOBOH8A3gE8O+flW12tCCOH3apt7\ncEQ1Yg/pYHnKEhLC4n0dkt9wpw/ApLVuvfCD1rpdKeXwYExCTDm9/TZe31PG/jP19PTbmJkRw12r\n81A5crLxtYr6TizpJYDzwS9xkTsJ4KhS6nlgO847htsYMrWjEIGuvaufn754jJqmbqLCg0mMCeNM\nWStnylq5b90M7lyd5+sQA9qp+mKCYlrJi5xBZlS6r8PxK+4kgC/jHPVzLc5O4FeAFzwZlBBThdXm\n4D9fPkFNUzc3LcviwRtnEWwxU1zTzi//dpq/vl9CsMXMrStzRt+Z8Ijz/UcgHD6QL5MYXm7UPgCt\ntUNr/Tut9T9qrb8IFAP/5/nQhPB/r+0upayukzUL0nj45gKCLc4/qZkZsXz7o8uIiwrhz1uLOFHc\n7ONIA1N9dyO9YVUE9cUxP7lg9A0CjFvPQSul0pRS31RKnQGeAwo9G5YQ/q++pYe391WQFBvGR2+Z\nfUVRscTYMB59YDGWIBO/fessHd0Dw+xJeMqbxdvABJksDuiib8MZtglIKRUM3A18BlgLvAFYtNaz\nvRSbEH7tb7tKcRgGD94wi7CQq/8p5aZFc9+6mby0rYjfv6v58n0LvRxl4OoY6ORo01EcfeEsSAjs\nom/DGekOoBb4N+A1IEdr/TDQ7ZWohPBz1Y1d7D9TT25qNMtU8ojr3rIym9lZsRwpbOR4UZOXIhQ7\nqvbgwI6tLp+8tMCb79cdIyWAV4As4AHgA0qpUKQMtBAAbDlcBcBda/Iwj9K0YDaZ+NitCrPJxPOb\nChmw2r0RYkDrs/XzftUezI5Q7E2Z5LomgReXGjYBaK0/D2QCfwC+gPOOIEsptchLsQnhl3r6rOw5\nXUdiTChLZiW5tU1WchQ3r8iiqb2Pt/aVezhCsbf2ID22XmjMJTEqgqhwKfx2NSN2Amute7XWv9da\nrweuA36LszDcHq9EJ4Qf2n2yjgGrgw1LMzGb3e9YvHtNPnFRIby1r4LGtl4PRhjY7A47Wyt3EmwO\nprs6i9y0GF+H5Lfcng1Ba12otf42kA086bmQhPBfhmHw/vEaLEEm1i7OGNO24aEWHrxhFja7gxe3\nnPdQhOJowwla+lopiFgAthByU6N8HZLfGvN0OFpru9b6dU8EI4S/q27sprqpm0Uzk4iJCBnz9tfO\nS6UgK5aj55s4VSrPBkw2wzDYVLEDEyYS+uYCyB3ACAJ7PjQhxmj/2XrAeSIfD5PJxEdvno3JBC9s\nOo/NLmW1JtO51vNUddWwLGUR9fXO5rm8NOkAHo475aDXXuW1uzwTjhD+yzAM9p+pJzQkiEUzE8e9\nn5zUaDYsyaSupYfNh6omMUKxuXwHABtz1lNe30l8dCgxkWO/UwsUIz0IlgPkA08rpR4bsigY+C9A\nmoFEQCmp7aCpvY/r5qcSGhw0oX19cN0MDpyt5++7S7lufipxUTLL6kRVdlZzrvU8Kn4WMeZk2rsK\nWVrg3iitQDXSHUA2znkAZgA/HPL1r8CvPR+aEP7l4NkGAK6dO77mn6GiwoO5b/1M+gfsvLStaML7\nE7C54uLVf1mdcw5gGf8/smHvALTWu4HdSqk3tdaveDEmIfzS8aImQkOCmJ+fMCn7W784g/eP17Dv\ndD3LCpK5Zk7KpOw3EDX1tnCk4QSZUenMTZjN62fLAGcpDjE8d8pBdyqlHtZav6CUeg5nWehvaa3/\n7uHYhPAb9S091Lf2smx2MpagyRk7YTabeOSueTzx7EGee+cc+ekxJMaGub19a2c/7xyqYvfxaupb\negkLCWJObjx3rsolJ8CufLdW7sRhONiYsx6TyTR4ByAdwCNz5zf534HNSqnbgAicCeCxEbcQYpo5\nUeIcsrlwxuRc/V+QnhjJhzcW0N1n4z9fPkFvv23Ubbr7rLy45TzffmYvL20upLG1l8zkSMJCgjh0\nroEnfneQzYcqJzVOf9Zl7WZvzQHiQ+NYnrIYgPL6TuKiQoiVvpURuXMH0Ku1blBK3QE8J1NCikB0\nsvhCAhj/6J/hrF+cQVVDF1uPVPPUn4/x6AOLiL7KMwYOh8H7J2r4644SunqtJMaE8pFb5zA/O47Q\nkCAMw+B0WQu/fuMsL2w+T1CQmRuWZk56vP5mZ9VeBhxW7spZS5A5iNbOflo7+90u0xHI3LkDCFNK\nfQ24HdiilJoBSGk9ETD6rXbOVbSRlRxFQoz7TTTuMplMfGRjAavmp1FS08G/P3uQA2frB58R6O23\nsftkLf/27AF+/47GanfwoQ0z+dEjq7j1ujxCQ4IG97MgP5HvfmwZ0RHBPP9eIaW1HZMerz8ZsFvZ\nXrWbCEs4q9NXAlBS0w7AzEx5AGw07twB/CPwCPAZrXWv6xmAf/FsWEL4j3PlrdjsjgmN/R9NkNnM\n5+6cS1pCOK/vKeOXfz9NiMVMRJiFjm4rDsPAbDKxZkEa962fSXz08E0bKfERfOGeBfz0T0f59Rtn\neOIzKyet38Lf7Ks9RJe1m9tybyTM4vw/Ka52Jr2ZGXKdOppRE4DW+oRS6n+Ama6XntVau3VZoZR6\nGmcROQN4VGt98CrrPAms0lpvcDtqIbzoQvu/JxMAOK/g71qTz8q5qWw5UkVhRRt9A3ZmZIYzNyee\ntYvTSYoNd2tfc3Pj2bAkg+3Hanj/eA03LsvyaOy+4DAcbKl8H4vZwvrsNYOvF9e0YzJBXrp0AI9m\n1ASglPoqzucBLDhnBXtCKdWgtR6xIJxSaj1QoLVepZSai7OS6KrL1pkHrAOs44xfCI8yDIOTxc2E\nh1q81qSQmhDBwxsnPvHePWtnsPdMPa/tKmXV/DTCQ9254Z86jjWeoqm3mTUZ1xIT4jzZ2+wOyuo6\nyU6OGnaWNnGRO/eFHwdWAi2un/8ZuNeN7W4C/gagtT4LxCulLv8LegppThJ+rLa5h6b2PhbkJxBk\nnlrNKLGRIdy6IpuOHiu7TtT6OpxJZRgGm8udRd9uylk3+HplQxdWm4MZmdL84w53UmSH1tqulAKc\n1UCVUu5MaZQGHB7yc6PrtQ4ApdSngB1AmTuBxsdHYLGM//H75OTAux2UY564Xaedxd/WLMn02//P\nkeJ68JY5vHOgki1Hq3notrkEjWH+An/WRB3lnZWszFrCgtwZg6/v140ALFEpfvt5jZcnjsedBFCq\nlPoXIE4pdTfwEHBuHO81+JunlEoAPg1sxDnr2KhaW3vG8ZZOycnRNDZ2jnv7qUiOeXLsPVEDQG5y\npF/+f7pzzKsXpLH9aDWb9pSwXE39p42Tk6P5y4m3AViXuuaS4z9e6CzXkRIT6pef13hN5Hd7pMTh\nzj3tFwE70AB8DjgOfMmN7WotpFroAAAgAElEQVRwXvFfkIFzWkmAG4FkYCfwKrDM1WEshN/o7bdR\nWNlGblo0sVO4ouRNy50dwDunSTNQRVs1p5vPMTM2n/zY3EuWFVW1ExlmITXevc7yQDdSNdCPaq2f\n11oPAP/h+hqL94AngGeUUsuAGq11J4DW+mXgZdf75AG/01p/bRzxC+ExZ8pasTsMFnng4S9vykyK\nJD89hpMlzbR19U/5yqOv6U0A3Jy7/pLXm9p6aWrvY9nsZEym6dHU5Wkj3QF8diI71lrvAQ675g/+\nBfAlpdSnlFIfnMh+hfCWkyVNgOeHf3rD9QvTMAzYe7rO16FMSGtfG7vLD5IWmcr8xDmXLNOVbQCo\nnDhfhDYleXSclGsO4aGOX2WdMmCDJ+MQYqwMw+BkSQtR4cHkp0/9J0pXzE3lT1vOs/tkHbetzJmy\nV8hbK3didxV9M5suvX49V9EKwJyceF+ENiWNlABWK6UqrvK6CTC01jkeikkIn6tq7Ka1s5/r5qdi\nngYjZ6LCg1k8M4nDhY3UNHWTmTz1Jkrvsnazq2Y/ieHxrEhdcsVyXdFGZJiFzORIH0Q3NY2UAI4C\nH/ZWIEL4kxPFruafKd7+P9RylczhwkYOFzZOmQTQOdBFeUclpR0VnG0uZMA+wB3qbizmS09dQ9v/\nzVP07sYXRkoAfVrrcq9FIoQfOVncjAlYMI0SwKKZSQSZTRzRjdy9Jt/X4VzB6rBR1VlNWUclZR0V\nlLVX0NTXcsk6s+Ly2ThjDZ1tlxYPOFvubP6R9v+xGSkBHPBaFEL4ke4+K0XVHczIjCEqPNjX4Uya\niDAL8/ISOFnSTENbLylxvhsqaRgGjb3NzhO964Rf3VmDzbj4jGmkJYJ5iYq8mBzXVzaRwRGEBYfR\neVn1mIvzNUyfhO0NI00J+S1vBiKEvzhd2oLDMKblyWS5SuZkSTNHdCO3Xeu9brwea8/FK3vXv93W\niw93BpmCyIrKIC82e/Bknxye5FZntc3u4HRpCylx4TL+f4ykWpIQlzle5J3qn76wZFYSJhMcOe+5\nBGB32KnuqqW0o8J1wq+goafpknUSwxKYE19AXmwO+TE5ZEVlEBw0vrut81Xt9A3YWbMwccqObvIV\nSQBCDOFwGJwsaSYuKoTcaTivbkxkCDMzYimubqer1zrhJi7DMGjpa73kyr6ysxqr4+LUlmFBYYMn\n+7wY5xV+dMjkdUJf6LBfPA0TtqdJAhBiiJKaDrp6raxbnDFtryYXzkigqLqdM2UtrJybOqZte219\nlHdUDmnOqaBzoGtwudlkJjMyjdxYZ7t9fkw2KRHJV4zZnyyGYXCsqJkQi1k6gMdBEoAQQxy/cDU5\na/peTS6cmcirO0s5Wdw8YgKwO+zUdtcPXt2XdlRQ392AgTG4TnxoHEuTF7qu7nPIic4kJMh7dZMq\nG7qob+lhuUomeALVggOVJAAhhjhe1ESwxcy8vARfh+IxOanRxESGcNLV2X1h3Hxbfztl7RWDbfcV\nHVUMOC6OtgkJCmFWXL6zk9bVnBMX6tu6+wfPOat/XjvGOxnhJAlACJem9l6qGrtZNDOR0ODpezVp\nNpmYlx/NgfLzvHz6PdqNeso6Kmnrbx9cx4SJ9MhUZ5u96+o+PTLVY00542EYBvvP1BMaEsRCaf8f\nF0kAQricKHaO/plunYkOw0Fdd8Ml7fY1EXWEzjXY4byAJiYkmsVJ811X99nkRGcRZgnzbeCjKKxs\no6m9j1XzU6d1wvYkSQBCuBx2zSa1eFaSjyOZmI6BTsraL47KKe+opM/eP7g82BxMbnQORedNpARn\n8LW71hMfGjflOr23Ha0GYP0St+aUElchCUAIoKN7gHMVrczMjCEhxr+vfIcasA1Q0l42pO2+kpa+\n1kvWSY1IYbFr+GV+bA4ZkWkEmYP40bnDFFe2E0rUlDv5t3cPcFg3kpkUSUGWzP87XpIAhAAOFzZi\nGLDCj6dMNAyDht4m19W986u6qxa74RhcJyo4kgWJc8iLySUvNpvc6Gwigq/+dOwC13DQs2WtXDPH\nf4/7at47WIHdYXDDsswpl7z8iSQAIYBDrtEk/nQi7LJ2X9GU02PrHVxuMQUxIyGXrPDMwc7axLAE\nt0+IC2ck8redpZwsafar4x5Ne1c/Ww9XExcVwtpF6b4OZ0qTBCACnj80/9gcNqq6aihrv9hR29jb\nfMk6yeGJzE+cM9hRmxmVQUZq/LgnC89NjSYqPJhTpS0YhjFlrqT/9J6m32rngQ0zZez/BEkCEAHv\nwNl6rzb/GIZBc1/L4NV9aUcFVZ3Vl1TCjLCEMzdh9mBhtLyYHKJCJneiE7PZxPz8BPafqZ8yk8QU\nVbXz1p5S0hMjWLc4w9fhTHmSAHxEV7RyrKiJAauDWVmxXKNSCLb4zxjrQGEYBu8fryXIbOLa+Wke\neY8eay/lnZVD2u4r6bJ2Dy43m8xkRaVfLHscm0OKm5UwJ2qBKwGcLGnx+wTQ1WvlV6+fxjDgUx+Y\nI38vk0ASgJf1W+389s2zg08wgnM425t7y/nHexeQmSTT2XlTWV0nVY1dLJ+dTGzkxEsY2B12qrtr\nhzTlVFLf03DJOolh8aj4WYPt9llRmYSMsxLmRM3Pdz7xfLq02avloceqq9fK0y8dp6m9j4c2zqYg\nS+r+TAZJAF5kszv4+UvH0ZVtzMyM4YNrZxARZuH947VsP1rNj58/wrceXur3V2LTyc4TtQCsHUdz\ngmEYtPa3OTtpXVf3FZ3VWIeUTwgLCnWd7HMGT/gxIf5TZTQuKpTslCh0ZTv9VrvfPVBlGM7qrH94\nV9Pc0c/qBWk8fOscmpu7Rt9YjEoSgBf98b1CdGUby2Yn84V75mMJct7C5qXFkJcWze/ePsd//fUk\n3/vkNUSGTZ+ZqPxVd5+VvafriI8OZUH+6LV/+mx9VHRWDV7dl3ZU0DFwsQPWhImMqLTBppz82BxS\nPVgJc7IsmJFAZUMXuqLNL+ZA6OgZoKy2g3MVbRwvaqK2uQezycTda/K4+/p8zOap0Vk9FUgC8JKj\n5xt5/3gNOSlR/MOd8wZP/hesW5xBQ2svb+0r5w/var5wzwIfRRo4th6ppn/Azj1rrjypOAzHxUqY\nrs7a2u76SyphxoXGsiR5weAJPycmi1AvVsKcLAvyE3l7XwWnSpp9kgAMw6Cwsm2wL6K5o29wmSXI\nzIo5KdyxKpecaTg/g69JAvCC3n4bf3yvkCCziX+4ax6hIVe/zb5v3Qx0RSsHzjZw7bxGlhYkeznS\nwNFvtbPlUCXhoRbWL8lwVsK8pCmnin77wOD6Iebgi5UwXU05vq6EOVkKsmIJDQ7iVGnL6CtPsor6\nTv74XiFF1c5CdJFhFhbOSCQ/PZqZmbHMzo7zu2ap6UQSgBe8vb+C1s5+7l6TN2L7vtls4lO3z+WJ\nZw/wwqZCFuQnyDhnDxiwD/Di3oP0xBSSmWvlh4d20drfNrjchIm0yJRLhmCmR6YSZJ6en4UlyMzc\n3HiOFTXR2NZLspcmi99xrJo/vleI3WGwtCCJjddko7LjpInHiyQBeFh7Vz/vHawgNjKED1ybO+r6\nmUmRbFyezTsHKth8uMqtbcTwHIaDhp5GSi88TdteQXVXHQ4cBOdAgwHRRhQLk+YNnvBzY7IJ9/NK\nmJNtwYwEjhU1caq0hRuWer642tv7yvnL9mKiwoP53J1zWTRzahfgm6okAXjY63vKGLA6eOjG/GGb\nfi53x+pcdp6o4Y095Vy/MJ3oiKnXruwrnQNdl7Tbl3dW0mu72KYcbLYQPJBAV3MU6wvmcdvCxSSE\nTb1KmJPtQif4qZJmjyeAvafr+Mv2YhJjQvn6h5eSlhDh0fcTw5ME4EEd3QO8f7yWpNiwMdUsiQwL\n5q7Veby4tYj3DlZy//qZHoxy6rLarZR3VFHcWkF1TxWV3VU0dF9aPiE1IplFSfMHm3L2H+nh7WNV\nLJmVxMMrFgb8if+ClPgIUuLDOVveis3uuGKQwmQpre3g2bfOEh5q4bEHl8jJ38emfQJo7ezntb3l\nhAaZWDk3lfjoUK+999YjVdjsDm5dmTPmP6gNSzN5e7+zGejWlTlEhQf2sFDDMGjsbaKso5KStnJO\n1hXTZm8E08VROWZHKCmWXFRSHgvTZpIfm0NEsPMEY7U5+Ov7xbx7oIrkuDA+ffscOflfZmF+IluO\nVFFc3Y7KiZ/0/fcP2PnV62ew2Q2++sB8eejRD0z7BFBS087fdhQD8MqOYj64dga3XZvj8T/+Aaud\nrUeqiQyzcP3CsVcsDAkO4gPX5vDi1iI2Hazkg+tmeCBK/9Vt7blkBqvy9kq6bT2Dyw2HCXpjiDZS\niDSS6W2Npr4OujFRDhyOaWZunkFCdChdvVaOFTXR0tFPakIEX39wsTSrXcX8GQlsOVLFqdIWjySA\nl3cUU9/Swy0rslmQ7/vnDUQAJIDlKoX/+9YN7DlWw2u7SvnL9mIa23r52K1qcDJsT9hzqo6uXit3\nrMp1u+3/cuuXZvLWvnI2H67k1pXZREzTh8NsDhvVXbXOwmjtFZR3VNDQ23TJOklhCeRHz+DsWehu\njmLNrNk8uFFdcmdkCQvm/UMVnChu5lRJC7tcT/kChAYHccuKbO65Pp/w0Gn/az8uc3LisASZOFnS\nPOnNjtVN3Ww9UkVaQgT3rw+sixl/Nu3/Ek43a545+TvMmAlfEoa928SeviCKt8VSkJ5MRHA4EZYI\nIgf/jbjktbCgsDHfLTgMg3cPVmIJMnHT8qxxxx4aHMSt1+bwl23FbDpUxT3X5497X/7CMAxa+lpd\ns1dVUNZeSWVXNTaHbXCdcEuYqxKms90+NyYbixHGE88epKutlw/fVMAtK7Kv2Hd8dBirF6SzekE6\ndoeD2uYe2rsHiAi1kJUcKUNqRxEWYqEgK46z5a20dw9MSm2kC17eVoRhwIM3zJLPwY9M+wSQHJ7A\n4rR5NHW20mPtwRregz24jyZaaaotG3V7s8lMhCWciOBwIi0RhLv+jQiOINISTkRwBBGWcFficL5W\nXNlLfUsX1y/MJC5qYn0ONyzN5O19FWw6WMnN12QTETa5H5lhGBwpbGT3yTrqWnqIjgjmGpXChqUZ\nk/KH2mvrpbyjarApp6y9kk7rxTouZpOZzMFKmM4TfkpE0iXlEwzD4P+9foaGtl4+cG3OVU/+lwsy\nm8lKjiJLnqUbkwUzEjhb3srp0mZWL5icyVbOlbdyvLiZ2dlxLJ4lTT/+ZNongJSIZL699ouXTJpR\n1djJD57fiyXEzufvm4052EaPtYceWy891h66bT30WHvpvuy15t5W7ENqto8kfCWcNIfwvT2RFxPF\n0GRxWdIYuizYHDx41xEWYuG2a3N4eXsxmw9XcveaybsL6Oq18sxrpzntegI0KjyY+tYezle1s/NE\nLV+9fyFJY3goyO6wU3OhfMKFSpjdDZeUT4gPjWNpyqLBk31OdCYho5RPOF7czL4z9czMiAm4vhBv\nW5CfyF+2FXOqpGVSEoDDMHhpWxHgvPqXjnf/Mu0TwNVkJUfzobXzeH5TIVt2dvHoA4vc+sU0DIN+\n+wA9rgTRY+uh23pp0qjvaOdoSQ2RUZCYYKbH2ktDbxP9XQOj7v8Ci9lySVIICwsnYlYX71YWYiqa\nSWxYpCtxOJurnAklgjBLqNuFxzq6B3jyj4epb+1lQX4CH76pgIykSDp7Bnj1/RK2H6vhJ386ync+\ntnzYkVOtfW2DHbWl7RVUdlYxMKQSZmhQCAVxM8iLzRm8wo8NjXH7/wGco3de3Hwes8n5lLSnhicK\np6zkSBJjQjle3ITV5phwzf2DZxsoq+tk5dwUZmSM7bMXnheQCQDghmWZHCls5ERxM4d1o1tzoppM\nJsIsoYRZQkkIu/ooiV/+/RQDRal89cNLmJd3scKkzWG7eDfhSh491l5X4rj6ax39ndRduIJ27eqd\nipLh48M02FwVGx5NCKGX9nG4kkaoOYxXd1TS0DvAhhW5fHjDvMF69NERIXzitjnERYXyt12lPPPa\nab7xkSVYHVYqO6tcbffOmjntAx2XvHd6ZCr5gyf7HNIiUyZcCXPzoUoa2nrZeE2WDBv0ApPJxHKV\nwnsHKzld1sKSWeN/Qtdqc/DKjmKCzCbuk2dZ/FLAJgCzycTHb1V879f7eXHreRbOSBz3aJ0LGtt6\nOXSukeyUKObmXpogLGYLMSHRY64F7zAc9Nn6aenp5Md/3o9hHuDh2/Kw0U+PzdVMNSRpXEgyZW1V\nl3SsXiEJwpJgP7vYv8N5tR5x4Y7CEkFEbDjpS/oobevjX3ZsostouaQpJzYkmsXJC4Y05WQRZpnc\nZyz6Bmy8vb+CiFAL906DDvCpYsUcZwI4dK5hQglg25Eqmtr7uPmabFK8VF9IjE3AJgCAtIQIbrs2\nhzf3lvPG3rIJD31790AFDsPgA5P4nIHZZHZexceGc9vChbyyo4Sm8oRR+wKSkqKoqW+5rB+jl/26\nksNFNcTFmVg0O4Y+R58zcbiWN/e2UG13DZ8MAUsKdNjN5MbkUJCQ66xzH+OshOnp9twdx2ro6rVy\n95q8aTsE1h/NyIghMSaUo+cbx90M1N1n5fU9ZYSHWrhrTd7kBykmhUcTgFLqaeA6wAAe1VofHLLs\nBuBJwA5o4HNaa4cn47maO1flsfd0He8eqOD6hemkjvPR9I6eAXadqCUxJowVcz0zufiNy7J490Al\n7+yvYP3iDGJHGGFkMpkICQohJCiEeJzT5x0738SBXQ3ERc/hO/dfM2zbvt1hH0waR4oa+MvbdUTN\nTuW+lQs9clxXY7XZeWd/BaEhQWy8ZvRRP2LyDG0GOlHczHI19qFUb+4tp7vPxodumBnwT7H7M4/1\nqCml1gMFWutVwGeBX1y2yq+AB7TWa4Bo4DZPxTKS0JAgPnxjATa7wfObCjEMY/SNrmLLoSoGbA5u\nXZlNkNkz/63hoRY+uDafvgE7r+wYvi/gaqoaunjm9dMEW8x85f6FI5bECDIHER0SRWpkCrctms/M\njDgOFzZSXtc57DaTbffJOtq7B7hxaaacQHxgjevp9Z0nasa8bVN7L5sPVZEYE8rGCTwHIzzPk0Mq\nbgL+BqC1PgvEK6WGDgNYrrWucn3fCPhsgPBylcz8vHhOlbZwpLBp9A0u0zdgY+uRKqLCg1m7aOxz\ny47F+iWZZCVHsetk7eAkGqPp6B7gP18+Qf+Anc/eOY+8NPdHY5hMJu5d6xx6+fddpeOKeawMw2Dr\nkSqCzCZudmPMv5h82SlR5KfHcLKkmZYhM3S546/vl2CzO7hv3Ux56MvPebIJKA04POTnRtdrHQBa\n6w4ApVQ6cAvwvZF2Fh8fgWUCv0zJySN3vn75oaV85WfbeGl7ERtW5BA2hnIBL27SdPfZ+Ohtc8jK\njBt3jO768oNL+M7/7uLZt8/xi3/aMGysycnR9A3Y+PELR2nu6OPhW+dw+9qx93OsT4rirf0VHCtq\nor3fzqwszx7jubIWqhq7WbMog4L8sXVCjvY5T0eeOuY7rp/Bf//lGEdLWvjwzcqtbXR5C/tO1zMj\nM5Y718/y2OQu8jlPDm92Al/xm6CUSgFeB76otW6+cpOLWlt7Rlo8ouTk6EseBLuaUBPcutLZIfy7\n10+53SHc0TPAK1vPEx0RzOq5KaO+z2RIiQ7h1hU5vHOggp/+4SCP3D3/irpGycnR1Na187+vnkJX\ntLJqfio3LUkfd3y3rczmbFkLL713jn+4a/5kHMawXt12HoBV88b2/+nO5zzdePKY52bFEBoSxBu7\nSli3IHXUq3mHYfC/Lx8H4MENM2lu7hpx/fGSz3ns2w7Hk01ANTiv+C/IAAarc7mag94GHtdav+fB\nONx256o8EmJCeWd/BVWN7v3yvrG7jL4BO3euzvNqkbEPrpvBrKxYDpxt4MXN53Fc1nfR3WvlF6+c\n4FhRE/Py4vn07XMnNGpnQX4CGUmRHDjbQGtn/0TDH1ZXr5UDZxtIjQ9nTu7kV6QU7gsPtXDD0kza\nuwbYdbJu1PX3nqqjpKaDlXNTmJ3t+TthMXGeTADvAQ8AKKWWATVa66Ep7Cngaa31Ox6MYUxCQ4L4\n2M0Ku8PgV6+dwWobeVBSaW0HW45UkRIfzoYlnp9Gb6hgi5mv3r+I9MQINh+u4md/OsqZshbqWnrY\nebyGL/90K6dKWlg0M5Gv3L9owk/Qmkwmbr4mC7vD2T7vKXtO1mKzO1i/JNOj1VqFe25dkU2wxcxb\ne8sYsA5fBqW9e4A/by0ixGLmQxtmeS9AMSEeu2TVWu9RSh1WSu0BHMCXlFKfAtqBd4FPAAVKqc+5\nNnlBa/0rT8XjriUFSaxfksGOYzW8tLWIj94y+6rr9Q/Y+e1bZzEM+ORtcyb8yPx4RIUH852PLec3\nb5zheHEz5yqODS4LMpu49/p8bl+VO2nlE1bNT+OVHSVsP1rNnavzCA2e3A4+wzDYdqwGS5CZNQvT\nRt9AeFxsVCg3Lc/inf0VvLG3jPvWXdk06jAMnnv7HF29Vj6ysYDE2MCaT3kq82ibhdb625e9dHzI\n996bmmuMPnxjAeer2tlyxDl71C0rcy5Z7jAMfvvWWaobu7lhWeYVT/16U1R4MF99YBGFlW0cK2qi\nq9dKWkIEt6+dicnmXuE6d4UEB7FhaSZv7Clj3+k61k/yXc+5ijbqW3pYNT9VJmzxI/esyefg2Xre\n3lfB4plJzMyMvWT5q++XcKyoibm58RMqfy68TyprXUVoSBCPfWgRsZEhvLi1iD9vPT94+9vdZ+WX\nfz/NwXMNzMqK5SM3Ffg4WmfzjMqJ56EbC/jsHfO4Y1UeKfGemWv1hqWZBJlNbD5cNe5nJoaz/Wg1\n4JwOU/iP0JAgPnX7XByGwS9eOUGxa/ix1ebgpW1FvLm3nJS4cP7x3gXSbDfFBHQpiJEkxYbz7Y8u\n4+cvn+DdA5XsOlFLelIklQ1d9A/YmZUVy6MPTLxtfaqJjw5luUrmwNkGzlW0TdrdT3v3AEcKG8lM\njmTWZVeYwvfm5yXwiVsVv39X88M/HCYvLZqWzn46ugdIjQ/naw8tkQf2piBJACNITYjge5+4hrf2\nlbP3dB1FVe2kxIWzfnUGN6/IDriT/wUbl2dz4GwDWw5XTVoC2HWiBrvDYMOSTKkZ76fWL8kkJT6C\nv+0soaSmg8jwYG6+Jpt7rpdaTVOVJIBRRIRZeGDDTB7YMBPDMOTkBMzMjCE3LZqj5xtpausd06Qx\nV+NwGOw4VkNIsJlV86Xz15/NzY1nbu7yweY/+XuY2gLzEnac5JfdyWQysXF5FoYBW13t9hNxqrSZ\npvY+rp2bOulTXgrPMJlM8vcwDUgCEOOycm4q0RHB7DxeQ/8I48PdsfWIM4ncuExGkAjhTZIAxLgE\nW8ysX5JJd5+NfadHf0p0OI1tvZwsbmZmhrNZSQjhPZIAxLhNxpDQ7ceqMXBO0SmE8C5JAGLcLgwJ\nrW7sRle0jXl7q83BzuO1RIUHs8KNOZmFEJNLEoCYkI3LnfX6Nx8ee32gvafr6Oq1snZRutSNF8IH\nJAGICblkSGh7r9vbORwGb+8rxxJkkikfhfARSQBiQoYOCd100P27gCOFjdS39rJ6QdqI01MKITxH\nEoCYsJVzU0mMCWPb0Sq37gIcDoPXdpdhwjkJjxDCNyQBiAkLtpi5d20+NrvB33eOPm/w3tN1VDV2\nsXpBGumJkV6IUAhxNZIAxKRYNT+NrORI9pyqG3Gy+p4+K6/sKMYSZOaD62Z4MUIhxOUkAYhJYTab\n+NgtzonDf/vm2WFnj/rTlvO0dQ1w56pcEmJk4hAhfEkSgJg0s7PjuGl5FnUtPfz2rbNXzFO8/Vg1\nu0/WkZsWze2rcn0UpRDiAqm8JSbVh26YSVl9JwfONmC1OfjITQVEhgfz7oEKXt9dRlR4MF+4Z37A\nltIWwp9IAhCTKtgSxGMPLOJ/Xj3F0fNNHD3fNLgsPjqURx9YRKqHZisTQoyNJAAx6SLCgvn6Q0vY\ne7qOQ+caGLA5UNlx3HRNFpEycYgQfkMSgPAIs9nEmoXprFmY7utQhBDDkIZYIYQIUJIAhBAiQEkC\nEEKIACUJQAghApQkACGECFCSAIQQIkBJAhBCiAAlCUAIIQKUybisYJcQQojAIHcAQggRoCQBCCFE\ngJIEIIQQAUoSgBBCBChJAEIIEaAkAQghRICSBCCEEAFq2k0Io5R6GrgOMIBHtdYHhyzbCPwIsANv\naa2/75soJ9cox3wD8CTOY9bA57TWDp8EOolGOuYh6zwJrNJab/ByeJNulM84G/gTEAIc0Vp/wTdR\nTq5RjvlLwMdw/l4f0lo/5psoJ59SagHwd+BprfV/X7ZsUs9h0+oOQCm1HijQWq8CPgv84rJVfgHc\nD6wBblFKzfNyiJPOjWP+FfCA1noNEA3c5uUQJ50bx4zrs13n7dg8wY3jfQp4Smu9ErArpXK8HeNk\nG+mYlVIxwDeAtVrr64F5SqnrfBPp5FJKRQL/BWwZZpVJPYdNqwQA3AT8DUBrfRaId/2yoJSaAbRo\nrStdV8Bvudaf6oY9ZpflWusq1/eNQKKX4/OE0Y4ZnCfFf/F2YB4y0u+1GVgLvOZa/iWtdYWvAp1E\nI33GA66vKKWUBYgAWnwS5eTrB24Hai5f4Ilz2HRLAGk4T3IXNLpeu9qyBmA6TFg70jGjte4AUEql\nA7fg/KWZ6kY8ZqXUp4AdQJlXo/KckY43GegEnlZK7XI1e00Hwx6z1roPeAIoAcqB/VrrQq9H6AFa\na5vWuneYxZN+DptuCeBypnEum8quOC6lVArwOvBFrXWz90PyuMFjVkolAJ/GeQcwXZku+z4T+E9g\nPbBUKXWHT6LyrKGfcQzwXWA2kA9cq5Ra7KvAfGjC57DplgBqGHIlCGQAtcMsy+Qqt1lT0EjHfOGP\n5W3gca31e16OzVNGOuYbcV4V7wReBZa5OhOnspGOtwko11oXa63tONuO53s5Pk8Y6ZjnAiVa6yat\n9QDOz3q5l+PzhUk/h1i28XEAAAH6SURBVE23BPAe8ACAUmoZUKO17gTQWpcBMUqpPFe74Z2u9ae6\nYY/Z5Smcowne8UVwHjLS5/yy1nqe1vo64IM4R8V8zXehToqRjtcGlCilClzrLsc52muqG+n3ugyY\nq5QKd/18DXDe6xF6mSfOYdOuHLRS6j9wjv5wAF8ClgLtWutXlVLrgB+7Vn1Fa/0zH4U5qYY7ZuBd\noBXYO2T1F7TWv/J6kJNspM95yDp5wO+myTDQkX6vZwG/w3lBdxL4x2ky1HekY/48zqY+G7BHa/1N\n30U6eZRSy3FetOUBVqAaZwd/qSfOYdMuAQghhHDPdGsCEkII4SZJAEIIEaAkAQghRICSBCCEEAFK\nEoAQQgSoaVcNVAhvUEpdA/wZWDqk3MZ/Af1a63/2aXBCuEnuAIQYB631IeD3uEpOKKWuBzYAj/sw\nLCHGRBKAEOP3Q2CRUuoe4JfAp1yFyoSYEiQBCDFOrjIMnwBeBF7TWh/2cUhCjIkkACEmZiFQCqxR\nSk3XCrNimpIEIMQ4KaXScE63uRFnVcav+jYiIcZGEoAQ4/cb4Ada6wsn/39yFWYTYkqQBCDEOLiq\nUaK1fs71byPOSUqedU3TKITfk2qgQggRoORKRQghApQkACGECFCSAIQQIkBJAhBCiAAlCUAIIQKU\nJAAhhAhQkgCEECJA/f/P4Gqy57IbIgAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ElPMpX053E1s",
        "colab_type": "code",
        "outputId": "0996e3f5-42dd-4659-eaaa-810227c66aa8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 585
        }
      },
      "source": [
        "MSE_list = {}\n",
        "for alpha in np.arange(0.001,0.3,0.01):\n",
        "  mlp = MLPRegressor(hidden_layer_sizes=10,activation='relu', learning_rate_init=alpha, random_state=0)\n",
        "  mlp.fit(X_train,y_train)\n",
        "  accuracy = mlp.score(X_test,y_test)\n",
        "  y_hat = mlp.predict(X)\n",
        "  MSE = mean_squared_error(y, y_pred)\n",
        "  MSE_list[alpha]= MSE\n",
        "  print(\"The learning rate is : {} and the MSE is : {}\".format(round(alpha,3) , round(MSE,4)))\n",
        "print()\n",
        "print(\" The minimum value for MSE is at learning rate: \", min(MSE_list.items(), key=lambda x: x[1]) )"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The learning rate is : 0.001 and the MSE is : 0.0083\n",
            "The learning rate is : 0.011 and the MSE is : 0.0083\n",
            "The learning rate is : 0.021 and the MSE is : 0.0083\n",
            "The learning rate is : 0.031 and the MSE is : 0.0083\n",
            "The learning rate is : 0.041 and the MSE is : 0.0083\n",
            "The learning rate is : 0.051 and the MSE is : 0.0083\n",
            "The learning rate is : 0.061 and the MSE is : 0.0083\n",
            "The learning rate is : 0.071 and the MSE is : 0.0083\n",
            "The learning rate is : 0.081 and the MSE is : 0.0083\n",
            "The learning rate is : 0.091 and the MSE is : 0.0083\n",
            "The learning rate is : 0.101 and the MSE is : 0.0083\n",
            "The learning rate is : 0.111 and the MSE is : 0.0083\n",
            "The learning rate is : 0.121 and the MSE is : 0.0083\n",
            "The learning rate is : 0.131 and the MSE is : 0.0083\n",
            "The learning rate is : 0.141 and the MSE is : 0.0083\n",
            "The learning rate is : 0.151 and the MSE is : 0.0083\n",
            "The learning rate is : 0.161 and the MSE is : 0.0083\n",
            "The learning rate is : 0.171 and the MSE is : 0.0083\n",
            "The learning rate is : 0.181 and the MSE is : 0.0083\n",
            "The learning rate is : 0.191 and the MSE is : 0.0083\n",
            "The learning rate is : 0.201 and the MSE is : 0.0083\n",
            "The learning rate is : 0.211 and the MSE is : 0.0083\n",
            "The learning rate is : 0.221 and the MSE is : 0.0083\n",
            "The learning rate is : 0.231 and the MSE is : 0.0083\n",
            "The learning rate is : 0.241 and the MSE is : 0.0083\n",
            "The learning rate is : 0.251 and the MSE is : 0.0083\n",
            "The learning rate is : 0.261 and the MSE is : 0.0083\n",
            "The learning rate is : 0.271 and the MSE is : 0.0083\n",
            "The learning rate is : 0.281 and the MSE is : 0.0083\n",
            "The learning rate is : 0.291 and the MSE is : 0.0083\n",
            "\n",
            " The minimum value for MSE is at learning rate:  (0.001, 0.008273983854967458)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8J8JsBvqaxX0",
        "colab_type": "text"
      },
      "source": [
        "**Problem 8**: Suppose you wanted to increase the performance of this neural network. How might you go about doing so?\n",
        "* You try different number of hidden layers and different number of neurons in each hidden layer.\n",
        "* Report your best Neural Network structure and the minimum MSE you can get."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7aLfE02a3p38",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Test with different number of hidden layers and different learning rates on each hidden layer\n",
        "def train_mlp(units, activation='relu', lr=0.071, batch_size=1000,loss_curve=False):\n",
        "    \n",
        "    mlp = MLPRegressor(hidden_layer_sizes=units, activation=activation, batch_size=batch_size, momentum=0.0, learning_rate_init=lr, random_state=0)\n",
        "    \n",
        "    mlp.fit(X_train, y_train)\n",
        "    accuracy = mlp.score(X_test,y_test)\n",
        "    \n",
        "    y_pred = mlp.predict(X)\n",
        "\n",
        "    MSE = mean_squared_error(y,y_hat)\n",
        "    \n",
        "    return MSE\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NYh_-Xtn3waG",
        "colab_type": "code",
        "outputId": "ea9a4619-49b4-4a5b-c71a-e1d48c989992",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 390
        }
      },
      "source": [
        "for units in range(5,110,5):\n",
        "  print(train_mlp(units), units)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.0168377700454656 5\n",
            "0.0168377700454656 10\n",
            "0.0168377700454656 15\n",
            "0.0168377700454656 20\n",
            "0.0168377700454656 25\n",
            "0.0168377700454656 30\n",
            "0.0168377700454656 35\n",
            "0.0168377700454656 40\n",
            "0.0168377700454656 45\n",
            "0.0168377700454656 50\n",
            "0.0168377700454656 55\n",
            "0.0168377700454656 60\n",
            "0.0168377700454656 65\n",
            "0.0168377700454656 70\n",
            "0.0168377700454656 75\n",
            "0.0168377700454656 80\n",
            "0.0168377700454656 85\n",
            "0.0168377700454656 90\n",
            "0.0168377700454656 95\n",
            "0.0168377700454656 100\n",
            "0.0168377700454656 105\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sZPFMVb23wdb",
        "colab_type": "code",
        "outputId": "d6f1da34-3e98-406d-9c7d-efbdd09c908e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 585
        }
      },
      "source": [
        "import itertools\n",
        "for i,j in itertools.product(range(10,50,10), range(10,50,10)):\n",
        "  units = i,j\n",
        "  print(units)\n",
        "  print(train_mlp(units))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(10, 10)\n",
            "0.0168377700454656\n",
            "(10, 20)\n",
            "0.0168377700454656\n",
            "(10, 30)\n",
            "0.0168377700454656\n",
            "(10, 40)\n",
            "0.0168377700454656\n",
            "(20, 10)\n",
            "0.0168377700454656\n",
            "(20, 20)\n",
            "0.0168377700454656\n",
            "(20, 30)\n",
            "0.0168377700454656\n",
            "(20, 40)\n",
            "0.0168377700454656\n",
            "(30, 10)\n",
            "0.0168377700454656\n",
            "(30, 20)\n",
            "0.0168377700454656\n",
            "(30, 30)\n",
            "0.0168377700454656\n",
            "(30, 40)\n",
            "0.0168377700454656\n",
            "(40, 10)\n",
            "0.0168377700454656\n",
            "(40, 20)\n",
            "0.0168377700454656\n",
            "(40, 30)\n",
            "0.0168377700454656\n",
            "(40, 40)\n",
            "0.0168377700454656\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bKfDnql83wj7",
        "colab_type": "code",
        "outputId": "13c44b08-c030-442a-e1fa-66341a98da98",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 372
        }
      },
      "source": [
        "num_hidden_units = range(10, 1000, 50)\n",
        "all_test_accuracy = []\n",
        "for units in num_hidden_units: \n",
        "    MSE = train_mlp((units,))\n",
        "    print (\"Units: {}, MSE: {}\".format(units, MSE))\n",
        "    all_test_accuracy.append(MSE)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Units: 10, MSE: 0.0168377700454656\n",
            "Units: 60, MSE: 0.0168377700454656\n",
            "Units: 110, MSE: 0.0168377700454656\n",
            "Units: 160, MSE: 0.0168377700454656\n",
            "Units: 210, MSE: 0.0168377700454656\n",
            "Units: 260, MSE: 0.0168377700454656\n",
            "Units: 310, MSE: 0.0168377700454656\n",
            "Units: 360, MSE: 0.0168377700454656\n",
            "Units: 410, MSE: 0.0168377700454656\n",
            "Units: 460, MSE: 0.0168377700454656\n",
            "Units: 510, MSE: 0.0168377700454656\n",
            "Units: 560, MSE: 0.0168377700454656\n",
            "Units: 610, MSE: 0.0168377700454656\n",
            "Units: 660, MSE: 0.0168377700454656\n",
            "Units: 710, MSE: 0.0168377700454656\n",
            "Units: 760, MSE: 0.0168377700454656\n",
            "Units: 810, MSE: 0.0168377700454656\n",
            "Units: 860, MSE: 0.0168377700454656\n",
            "Units: 910, MSE: 0.0168377700454656\n",
            "Units: 960, MSE: 0.0168377700454656\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tBEY3OVX3whL",
        "colab_type": "code",
        "outputId": "bc39cadb-8ae0-47b8-8112-a6ca6fb67cb1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 194
        }
      },
      "source": [
        "units = num_hidden_units[np.argmin(all_test_accuracy)]\n",
        "optimum_depth = []\n",
        "\n",
        "for depth in range(1, 11):\n",
        "    MSE = train_mlp((units,)*depth)\n",
        "    optimum_depth.append(MSE)\n",
        "    print (\"No. of Neurons: {} , Depth of the Network: {}, Mean Squared Error: {}\".format(units,depth, MSE))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "No. of Neurons: 10 , Depth of the Network: 1, Mean Squared Error: 0.0168377700454656\n",
            "No. of Neurons: 10 , Depth of the Network: 2, Mean Squared Error: 0.0168377700454656\n",
            "No. of Neurons: 10 , Depth of the Network: 3, Mean Squared Error: 0.0168377700454656\n",
            "No. of Neurons: 10 , Depth of the Network: 4, Mean Squared Error: 0.0168377700454656\n",
            "No. of Neurons: 10 , Depth of the Network: 5, Mean Squared Error: 0.0168377700454656\n",
            "No. of Neurons: 10 , Depth of the Network: 6, Mean Squared Error: 0.0168377700454656\n",
            "No. of Neurons: 10 , Depth of the Network: 7, Mean Squared Error: 0.0168377700454656\n",
            "No. of Neurons: 10 , Depth of the Network: 8, Mean Squared Error: 0.0168377700454656\n",
            "No. of Neurons: 10 , Depth of the Network: 9, Mean Squared Error: 0.0168377700454656\n",
            "No. of Neurons: 10 , Depth of the Network: 10, Mean Squared Error: 0.0168377700454656\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_rQ8QzlO8X3m",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}